{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_o70WfKQFTd"
   },
   "source": [
    "# Sparse Retrieval for Natural Questions RAG\n",
    "\n",
    "This notebook demonstrates [PyTerrier](http://github.com/terrier-org/pyterrier) and [PyTerrier-RAG](https://github.com/terrierteam/pyterrier_rag). This notebook runs on Google Colab if you select a Runtime with a T4 GPU (these are free to use), and will take approx. 12 minutes to execute fully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6iZau7_QP9v"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Lets install what we need:\n",
    " - PyTerrier - core platform\n",
    " - PyTerrier_t5 - MonoT5 reranker\n",
    " - pyterrier_rag - Support for RAG datasets and answer generators (aka readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uatJzx1kQ7_J",
    "outputId": "347f52f9-6439-4151-e098-c85994e8d81e"
   },
   "outputs": [],
   "source": [
    "#%pip install -q --root-user-action=ignore python-terrier pyterrier_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvFoJULYRAqq",
    "outputId": "a52b7574-5fa7-4d21-ebcb-f77afe4b06d9"
   },
   "outputs": [],
   "source": [
    "#%pip install -q  --root-user-action=ignore pyterrier-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "kHFMfW1uPZhS"
   },
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "pt.utils.set_tqdm('notebook')\n",
    "import pyterrier_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrI7rYO4Qeb2"
   },
   "source": [
    "## Retrievers\n",
    "\n",
    "Lets load a sparse index of Wikipedia. Conveniently, we've stored this as a [Huggingface dataset](https://huggingface.co/datasets/pyterrier/ragwiki-terrier). This is 12GB in size (it also contains the text of the documents) - downloading takes about 10 minutes on Google Colab.\n",
    "\n",
    "We'll use that index to get a BM25 retriever (you can see how this was created at https://huggingface.co/datasets/pyterrier/ragwiki-terrier#reproduction). \n",
    "\n",
    "Terrier doesnt like question marks in queries, so we'll strip these and restore them after.\n",
    "\n",
    "Finally, lets make a monoT5 reranker, which we will use to rerank BM25.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783,
     "referenced_widgets": [
      "6390c0d2ef0e4ca5acf1530bc958ccae",
      "9062ea2922fc4a9687c22a35813cc13b",
      "af915153635a4480b299b769df35fc6e",
      "c38c083cabef431093eb443e93e52a1a",
      "c45314fbed7e4726865dd6cf6425fbea",
      "4be825db5ecb454cbe6c91af0becb3c5",
      "d53c269b5b6e4bab90130f81fc200834",
      "43c47090cd934ca6a34ef99888646cd0",
      "531e568d344b481985c95e444c10d2c0",
      "ea9bd020f78a4d16b16d73adfd373447",
      "3dfdd0041b15472fad7696e5ea9d692a",
      "d2aee0e3177d455483a2ac8382c3762b",
      "623b51385536462190565212d2b3a6c9",
      "500fb33008f54e998058cf4574919d07",
      "72a939bc0a014edf99ed72824226a0c4",
      "341d1ecf2b6d4608946e010276f1da84",
      "f4521b2151134ca4a6d54b4d31b7dbd0",
      "318d3f0c8c9d4f1a995bdf65b0895ad6",
      "2185643db9904fbcb8f127d23da15aa4",
      "13e58ae8c1474acba14fd08e8d9eddd7",
      "e6301414593d4f5098b63ca08a157ec8",
      "8a496a95dd504f8aa3cd1eec28e94aa2",
      "d7687d62fba0436382a3a731e299df57",
      "91551bd2ab6c430999a64275b590d938",
      "00eb6addc6da4f258eb9927a085e5d4e",
      "244c43e1b06346e6a56b21c99c44af69",
      "4e6ed91babcc49e7801b18285d5c756d",
      "992874a87acf415b8c2479e74c65dbe9",
      "36d13de0cb624e9a836f3bfda3516770",
      "19b06d7509844359a9b99941ee558a7a",
      "cdc7985ccd9d4573ba671075a4e794c1",
      "eb9546f23df04d0cb3257624fd79fd1c",
      "15d875b2559242ad82f926db09ffed33",
      "3bd15ac2d6814b3cb8ac31644c90d9bd",
      "0e6827007a854ccfa74f09d8f17d0ca7",
      "78497b79fe544af89322339fe3220dc4",
      "5d8f5335702a4822b0cbe90a9242e9ca",
      "11da3cc1945449a0a8bb94d71df08078",
      "28d5af1bfead42879f338dfbb99cccfa",
      "60999fb90db84a20a71368d4eae272bd",
      "175ac3f821ce472ca0e633c8d6d98b13",
      "dd6a16430bda4df0a45d5c4c9dbf11c6",
      "0fb30c69859942378ea925fa6b710e7e",
      "135dab5311a34e1692056ac4746b1a62",
      "4a1d22c856574b04a2f0045b26435edc",
      "4d10f9ff60a44c37b3395c82b608e5df",
      "5a0a28fad28542beb70fe8bb8841a6b6",
      "9e585fd56b8248ff836f3422d1debd93",
      "449940861e1349eaa7b2ba43afbb09fb",
      "61c8620217f948258a57a9b4d61c791f",
      "f7cef11c1f68455aac25a364c1a4157e",
      "7fe368acce2144eea9a7ee8c02210df6",
      "88525152c40743d4a0a0007f1218d4eb",
      "ef4fb8e3026945eba8185bb85fb214d6",
      "3d7216f1edf14b728abf77a55080c937",
      "38534fcb9a1246f9afcfbf303016778a",
      "ccfca650361a4020b9a46d4eeb90e5f3",
      "b44aded8c967484eb97eea2ef4ec5cdd",
      "4b5c7930c82245e3b476bce2515b723d",
      "56f26486dd144cdd9913812af1d3bae5",
      "04da27bde4f9464eb4ab7fb3e870cc7c",
      "bc694ecc84694c1088b7069b668a728f",
      "bda88bc8168443c5899ee3cea8c17cbe",
      "e1d93b72cebe49b4b97f7c8a83ee4e50",
      "75e46e5e7bf0423c9e4346176cd0f067",
      "1e7f428b71db46dfb1fe88c49d3cf92f"
     ]
    },
    "id": "BybUPDh6Qy33",
    "outputId": "9c859371-a566-496a-ebeb-19d4b84f848e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/rag/lib/python3.11/site-packages/pyterrier/terrier/retriever.py:208: UserWarning: Multi-threaded retrieval is experimental, YMMV.\n",
      "  warn(\n",
      "/opt/miniconda3/envs/rag/lib/python3.11/site-packages/pyterrier/terrier/retriever.py:215: UserWarning: Upgrading indexref /mnt/resources/pyterrier-cache/artifacts/ebfd80cc597a31719f11ab5cd11ad8f441bc460f760c82ff66413ba9fb06943f/data.properties to be concurrent\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from pyterrier_t5 import MonoT5ReRanker\n",
    "\n",
    "sparse_index = pt.Artifact.from_hf('pyterrier/ragwiki-terrier')\n",
    "\n",
    "bm25_ret = pt.rewrite.tokenise() >> sparse_index.bm25(include_fields=['docno', 'text', 'title'], threads=5) >> pt.rewrite.reset()\n",
    "monoT5 = MonoT5ReRanker(batch_size=64, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5j2yqwJ-RJXJ"
   },
   "source": [
    "Lets formulate our monoT5 reranking pipeline - we'll take the top 10 documents from BM25 and rerank those using monoT5. Here we are using two PyTerrier operators to make a pipeline:\n",
    " - `%` - apply a rank cutoff to the left.\n",
    " - `>>` - compose (aka. then), which means apply the right handside on the output of the left hand side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "5cMn5JvMRItr"
   },
   "outputs": [],
   "source": [
    "monoT5_ret = bm25_ret % 10 >> monoT5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ns_W7XucRmew"
   },
   "source": [
    "Lets compare the results..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "S8idFu1bRfh6",
    "outputId": "cde0d954-80b0-4a8f-8e99-c7999b2c109e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1027780</td>\n",
       "      <td>1027780</td>\n",
       "      <td>Chemical change Chemical changes occur when a ...</td>\n",
       "      <td>\"Chemical change\"</td>\n",
       "      <td>0</td>\n",
       "      <td>29.908465</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53321</td>\n",
       "      <td>53321</td>\n",
       "      <td>are called reactants or reagents. Chemical rea...</td>\n",
       "      <td>\"Chemical reaction\"</td>\n",
       "      <td>1</td>\n",
       "      <td>29.825437</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>860125</td>\n",
       "      <td>860125</td>\n",
       "      <td>Chemical reaction A chemical reaction is a pro...</td>\n",
       "      <td>\"Chemical reaction\"</td>\n",
       "      <td>2</td>\n",
       "      <td>29.526942</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid    docid    docno                                               text  \\\n",
       "0   1  1027780  1027780  Chemical change Chemical changes occur when a ...   \n",
       "1   1    53321    53321  are called reactants or reagents. Chemical rea...   \n",
       "2   1   860125   860125  Chemical reaction A chemical reaction is a pro...   \n",
       "\n",
       "                 title  rank      score                         query  \n",
       "0    \"Chemical change\"     0  29.908465  What are chemical reactions?  \n",
       "1  \"Chemical reaction\"     1  29.825437  What are chemical reactions?  \n",
       "2  \"Chemical reaction\"     2  29.526942  What are chemical reactions?  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bm25_ret%3).search(\"What are chemical reactions?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "WZRtspglRkbL",
    "outputId": "8f8a3d15-aef4-4758-86c4-fb2f1c4da7ba"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>query</th>\n",
       "      <th>score</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>860125</td>\n",
       "      <td>860125</td>\n",
       "      <td>Chemical reaction A chemical reaction is a pro...</td>\n",
       "      <td>\"Chemical reaction\"</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "      <td>-0.029645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>53321</td>\n",
       "      <td>53321</td>\n",
       "      <td>are called reactants or reagents. Chemical rea...</td>\n",
       "      <td>\"Chemical reaction\"</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "      <td>-0.080680</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3147077</td>\n",
       "      <td>3147077</td>\n",
       "      <td>the course of a reaction. Reaction mechanisms ...</td>\n",
       "      <td>Chemistry</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "      <td>-0.658413</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid    docid    docno                                               text  \\\n",
       "1   1   860125   860125  Chemical reaction A chemical reaction is a pro...   \n",
       "0   1    53321    53321  are called reactants or reagents. Chemical rea...   \n",
       "2   1  3147077  3147077  the course of a reaction. Reaction mechanisms ...   \n",
       "\n",
       "                 title                         query     score  rank  \n",
       "1  \"Chemical reaction\"  What are chemical reactions? -0.029645     0  \n",
       "0  \"Chemical reaction\"  What are chemical reactions? -0.080680     1  \n",
       "2            Chemistry  What are chemical reactions? -0.658413     2  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(monoT5_ret%3).search(\"What are chemical reactions?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xnPLza6uRnzW"
   },
   "source": [
    "Interestingly, the re-ranking had some impact - 860125 was 3rd under BM25, but became first under monoT5 - while order many not matter so much for our readers, the inclusion of 3147077 and removal of 1027780 would likely change the reader's generated answer.\n",
    "\n",
    "\n",
    "You'll see that all of our retrievers give as output the same columns:\n",
    " - qid - unique identifier of the question\n",
    " - query - text of the question\n",
    " - docno - unique identifier of the passage\n",
    " - title and text (of the passage)\n",
    " - score and rank - to invoke an ordering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuYGD1c4RCdx"
   },
   "source": [
    "## Readers\n",
    "\n",
    "### Fusion in Decoder\n",
    "\n",
    "Lets now see the readers that will generate the answers. The first one we use is Fusion in Decoder - a T5-based model that encodes each document separately, but combines these representations in the decoder step.\n",
    "\n",
    "In PyTerrier terms, a reader takes as input the following columns:\n",
    " - qid\n",
    " - query\n",
    " - docno\n",
    " - title & text\n",
    "\n",
    "And returns:\n",
    " - qid\n",
    " - query\n",
    " - qanswer\n",
    "\n",
    "We provide a checkpoint trained for NQ on Huggingface at terrierteam/t5fid_base_nq.\n",
    "\n",
    "We further formulate two RAG pipelines - one using BM25 and one using monoT5 as input to FiD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "be7da14a151b45b0abb1baafb7e88993",
      "55634ab2259640d288f61815a948e512",
      "e817d5b418d94c7088264c1db8547fed",
      "f770920ee9084dd492c396535d8f4bcf",
      "990d4e4cf8444eacba298043a791df21",
      "4fff7a74678740eab6c2b6eadef66fd9",
      "02305c87e8ee499aacc68cad59016aae",
      "62a3fbdeef1b496ea0848f527447ff14",
      "0c82a75e57ae4c21ab54979c5f8bab1d",
      "9f9a5ed0cf0a4e1aa5aff88b2bdc69b8",
      "4210fdbe21d74264a6ff71b350037136",
      "ad6cd3ea8f4f4e99a5b8056c8d374606",
      "145b56f8b10741a88c1460eda88f4378",
      "7b92eb472d8b45859437ebf18415acc6",
      "1ed0b9960e4d4925a3c08a1e70a145dd",
      "382347e1bb7d4fdfa727db905ca4779f",
      "b58d0267f1c048d299d9899b6df6f1aa",
      "eb09336a8d9e496e845e3631599e5411",
      "cd098a515a884839acd1e29507c9d37a",
      "661a2cd4f843428b880b0017d7d63d0f",
      "18ce6263244f444484c28c3398a53ea0",
      "b992877edc184ac299aeaefff99e0177",
      "8b725c45da554d5cb2483ff292f0ba20",
      "2a7f9f438e32413893b1d9faadbc24e4",
      "b1e4e1ae19fc48cf945e6256abc6bd03",
      "1180cba9eedb4cadb1366a9a5ae1bef0",
      "f4c0c2925fd84d9ba727d0c3e4161dc1",
      "85c72d08334d42e6872445e352537693",
      "09cc45c92c044b49ace60233d3db9204",
      "c362e9cea66749c3ad5879eec0c99a20",
      "12bf293b38754c71adba7f9a86f9379c",
      "4a6f8879166d4266a1733d174488e052",
      "793ad289385142b7b55cf9f4428db9ae",
      "3f53b8aa84954ab6abc6d6f5f098d891",
      "e0a49a73f6784a7f80b5af6afe6dd9dd",
      "c34e43f299014e729fd71edefa1456f0",
      "d4941bffa4454135a7e28912b796e28a",
      "e722237e5ea94fbfaf7f955d2564d2c5",
      "f259978c7fe8406c81ee4a9481471188",
      "ede98007980a452a97776bf84f01382b",
      "d5900dd4a5cc414aac1b943e245081f5",
      "ef583dd749d4425abeb5741fe76a4c48",
      "cab94417c0034ade9d83d0026c45779a",
      "99e3289ad8d3428cab5221d655310004",
      "0306f8cd525641f2ac79a140ced16db9",
      "1f55f256db92438bbb1786cf828a6dd3",
      "9eb9adbd507b4861a34f05cd5398dd51",
      "0124987d38834155bdbdac7c5f2262e9",
      "1ad55368a5294e0e83e5157cea1b89c5",
      "4a603ab9be704e3ab38cbd48716190c9",
      "5c251032748c478ebed87e4f753d31f4",
      "9706429f4bb9407eaac351e7f3695486",
      "5cf3f19ebcbb491bb6b96b2875d10399",
      "c3b75d20fcba4a84bdbb679d9fefc464",
      "d2250486a0ca4ce08e8827536ebfef5d",
      "b34eca238a6e4d46978bc1338beb76ab",
      "9fb9ab2aebed4a999d382d8f3e950fb2",
      "63085e000d2742fbb6002f32f1108bea",
      "5daf8270330e49c086c4457679ab821f",
      "a720275c96e34353b2ed3850dcd62e59",
      "818ca82fa230476e9747a5ed5cd555c8",
      "a5753e98ec13461282b7440774875cb5",
      "3f0978aaa55c4cc5b56b170df62eb309",
      "b52bdab8efa14fdaa4ba68f01ac73b3b",
      "f2caaf8f265246e3a80253c09bc15500",
      "dbf4c12cce6d4342bd5171b60daa7793"
     ]
    },
    "id": "1uUqwgkSRRkk",
    "outputId": "0ca5ebd4-8e59-4847-81a3-9444a6d51b0a"
   },
   "outputs": [],
   "source": [
    "import pyterrier_rag.readers\n",
    "fid = pyterrier_rag.readers.T5FiD(\"terrierteam/t5fid_base_nq\")\n",
    "\n",
    "bm25_fid = bm25_ret %3 >> fid\n",
    "monot5_fid = monoT5_ret %3 >> fid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rVm--ixWhyP"
   },
   "source": [
    "When we invoke search on this pipeline, we now have a qanswer column that contains the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 81
    },
    "id": "YXIGgxY0W6H9",
    "outputId": "e0b8314e-d67d-4e13-f496-e8727008b04c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>qanswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "      <td>chemical equations</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                         query             qanswer\n",
       "0   1  What are chemical reactions?  chemical equations"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monot5_fid.search(\"What are chemical reactions?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6P8VZannWokl"
   },
   "source": [
    "### FlanT5\n",
    "\n",
    "Our second reader is FlanT5 - an instruction-tuned model - we use it zero-shot.\n",
    "We instantiate it using a backend (`Seq2SeqLMBackend`), and giving that to a Reader class.\n",
    "\n",
    "`Concatenator` takes the document text and titles (returned in the retrieval part of the pipeline) and puts it into the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 360,
     "referenced_widgets": [
      "405437a8a1394a0fa22dd60af0aac15d",
      "b7b862abd74140689f98f22477a6353a",
      "639eea8b24054ccdb6c20c7a1f9ecdc6",
      "dc3320d096ea44009a294b590f37967f",
      "7e9d7799403145158e5fdbb578382448",
      "e2672c4d64c94acaa4a255ed75b1a0a5",
      "6cd4a9f6f9394262af30da6164920353",
      "eba293dded4445bd8b43f143d1ab8c6e",
      "2baafff5425640bdb46c6a1fa03cd76e",
      "2e94f7d3d9de4e30a8a8d2af3b184128",
      "89e9cfaae0594199959f15855f3f499e",
      "f175e8e0c0d0445cbf7124f8d67a338e",
      "fa376fa0452e43b9812c012c64bb2dcf",
      "f2ab3a3b6b244030bdf067c3a41b7793",
      "e821fe2f65784de7aa07ea9568b8051c",
      "ab530a81d25043bf9dd1613c2586d260",
      "e64a44fd35ea4950b44785954b1e3bce",
      "428c2a5ec009434a9e45557cf271988a",
      "591977fd335d497799894148f2f34342",
      "fae9e1dc2edc43c2997a8e3f51d07e00",
      "5d01a053940744f087393f7b3d6834ee",
      "6e8b0ccd89804802b21607d38c02fb4b",
      "384e49ee2ac04c77982d2e8bed0ae5d6",
      "98dcbd2ce94647889241aef9ec065d22",
      "0706eaa19cfd489fba2884fe235f5482",
      "0e5a2fef2ce84f7cb200c089255d88fc",
      "c386d6e5a88442ef876bc0229b1777dd",
      "68d0ed37da8946c289bd4eb6ab8fdc21",
      "0878fa037d7e44529bec04c278410604",
      "97e9d09775334b3f90c6860bec6ea55a",
      "307ae02dc3ea4df5bbdc173b4fccaa48",
      "21d0ba3ae74f4ff48c6d394643e3e3c4",
      "f360de00d5e54098aa709fceeaed98da",
      "f36e6b8201884e6a8ca3f5af449da445",
      "3e4ae8ac57ba46239bd95c406026f12d",
      "6db9dae88b4648fbb61f91b60c5d70e9",
      "e2fdcc81e37549779a91504448b3fea8",
      "82220ab9b9314ced8b4d77ee31f40f87",
      "fb3cca7bb10540e89d4ce734f34191c1",
      "1a5c62a193e34f11a0631d3c8f7b2479",
      "4d5210877ba24983b5f60cffa8b02de6",
      "132fdca5ea724e4389e41ca2815793bf",
      "2ae057cf1dfd4aa8a82ba131848ba870",
      "b99735e8688149c0a3b2aac886787a84",
      "ada1b1ae9226426ba736d22c242ad030",
      "027185dabe3a4ab49447b082730ffe98",
      "7992c9eb24614b078885aaa0f3b64a1f",
      "b0604307f0c94536902ce31d7ad55d24",
      "0211b263c51845a3b526cea19ddfe708",
      "6c60be7d523e4cb3b076c182b186d67c",
      "3d330670e50a41f5bb869913a50822ac",
      "f6dd45b28353430da10b0d55802c6297",
      "44e9d61764ee4bc3b558de279719f3b5",
      "33b150227a1241e3846e3f2f6125a834",
      "866bc519bef248d98fb9d8cf93f01bd7",
      "13c42b8fbe8e4f62a03a519891d8f5c0",
      "4960f290795048c1b9e3582e1182ba74",
      "5b48b714858c477f96bc3e88e6554427",
      "0c1dfdc272de4948a70f81bfaa3fb28f",
      "2410d313b3ce4542a987dd45c2ca4266",
      "900015f035a0482da78674915d712b6b",
      "a7d472d379dc4e14a14475f726e0e774",
      "21c2c9af02234f6fa72de026dfcc524b",
      "31e31e2766d8408eb87a33624ddfdb41",
      "158e759bdd2f4f1a99db88f0eaa71047",
      "d727cda02949443797b51fa36302fc4e",
      "fd2ae03c3cbf48b3815e2d062facd9a2",
      "9653fefe1f8f429fb28b3899d2ff3155",
      "e0fa4e8192b440268c7301fa97172734",
      "ff101361a9134563aa0006af87abbd60",
      "1dcfe5b4d54940d0bed59fbab6731e30",
      "b3294666e3974349b7d175a1de462448",
      "301a64d615404a39afa5c840b8564a76",
      "60c70bb4a0a24722be154c9603a15bb9",
      "0e191c9aeb504f639df046965c166d62",
      "3f81844314254ee599dbc19627ad94ce",
      "1cdc3695ddc448febb7ffb4d1a99c3e9"
     ]
    },
    "id": "lFnukKkP80_A",
    "outputId": "5b8f7013-2604-4a95-e5d0-8a9748d0299e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>qid</th>\n",
       "      <th>query_0</th>\n",
       "      <th>qanswer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n### Human: Use the context information to an...</td>\n",
       "      <td>1</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "      <td>a process that leads to the chemical transform...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt qid  \\\n",
       "0  \\n### Human: Use the context information to an...   1   \n",
       "\n",
       "                        query_0  \\\n",
       "0  What are chemical reactions?   \n",
       "\n",
       "                                             qanswer  \n",
       "0  a process that leads to the chemical transform...  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier_rag.backend import Seq2SeqLMBackend\n",
    "from pyterrier_rag.prompt import Concatenator, PromptTransformer\n",
    "from pyterrier_rag.readers import Reader\n",
    "\n",
    "prompt = \"Use the context information to answer the Question: \\n Context: {{ qcontext }} \\n Question: {{ query }} \\n Answer:\"\n",
    "prompt = PromptTransformer(instruction=prompt, system_message='')\n",
    "\n",
    "flant5 = Reader(Seq2SeqLMBackend('google/flan-t5-base'), prompt=prompt)\n",
    "monoT5_flant5 = bm25_ret % 10 >> monoT5 %3 >> Concatenator() >> flant5\n",
    "results_flant5 = monoT5_flant5.search(\"What are chemical reactions?\")\n",
    "results_flant5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pUIocpDYvLY6"
   },
   "source": [
    "Interesting to see that the answer by FlanT5 is a bit longer and detailed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APGF5E99RrlR"
   },
   "source": [
    "# Datasets & Experiments\n",
    "\n",
    "Lets compare the effectiveness of these three approaches on the Natural Questions dataset. These topics are automatically downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "W--MmMYZSqSP",
    "outputId": "7a72e880-1eb8-4bc0-c60c-1a69595688d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_0</td>\n",
       "      <td>who sings does he love me with reba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_1</td>\n",
       "      <td>how many pages is invisible man by ralph ellison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                                             query\n",
       "0  dev_0               who sings does he love me with reba\n",
       "1  dev_1  how many pages is invisible man by ralph ellison"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset('rag:nq')\n",
    "dataset.get_topics('dev').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scU0jppYSz3C"
   },
   "source": [
    "And their corresponding gold truth answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "ESvmPzxYSwr4",
    "outputId": "6af066c0-0c0a-4968-81b9-e44ce5af7322"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>gold_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_0</td>\n",
       "      <td>who sings does he love me with reba</td>\n",
       "      <td>Linda Davis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_1</td>\n",
       "      <td>how many pages is invisible man by ralph ellison</td>\n",
       "      <td>581 (second edition)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                                             query  \\\n",
       "0  dev_0               who sings does he love me with reba   \n",
       "1  dev_1  how many pages is invisible man by ralph ellison   \n",
       "\n",
       "            gold_answer  \n",
       "0           Linda Davis  \n",
       "1  581 (second edition)  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_topics('dev').head(2).merge(dataset.get_answers('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0I13hlRSubW"
   },
   "source": [
    "Now lets run an experiment using Natural Questions.\n",
    "\n",
    "They first four arguments correspond closely to main details our our experiment - specifically, we're going to compare: `bm25_fid`, `monot5_fid`, `monoT5_flant5`, on 100 dev topics (this take about 2 minutes). We'll evaluate our answers using Exact Match and F1.\n",
    "\n",
    "The additional arguments are:\n",
    " - `batch_size` - how many queries to run and evalate at once. Not always necessary, but makes the progress bars more granular\n",
    " - `verbose` - display progress bars for this experiment\n",
    " - `precompute_prefix` - optimise the experiment such that BM25 is only computed once.\n",
    " - `names` - for naming rows in the output dataframe\n",
    " - `baseline` - we'll compare to monoT5 with FiD, to see how much it helps compared to BM25, and how much FlanT5 does better than FiD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261,
     "referenced_widgets": [
      "0b906a0b2bac4b5c82f6e0e755c741c3",
      "9bb0dba3926443d5accb32fc4d80c2f3",
      "9d4c6e635ab7446b9e0251f25f3be922",
      "fa1c9fd792374b209a86238bb12887d2",
      "7575e4075e7d4160b0db458d50446ce1",
      "82b5af984be14d3da362ad5b57410e74",
      "aecd5d1faa6b41a9b7bf78f2e7bec9b0",
      "4551e6e37d494519bc36f8ad9cc710ed",
      "819d1c120f4d498fa9d63633f9462e76",
      "c3c4a2936498494c9bca162012237484",
      "745f2a10770843b988e9367aab21b193",
      "baa8e017f9e24b8785ebcafbd036ec26",
      "fbcac39d19044cca86fb7d8e03ead7ee",
      "acef8f3219ec4156878e4fde76373e67",
      "2587e313646540b0ae84b11e703852d8",
      "3c2b33cee12e4bfb83fa2d5bf9d67c6b",
      "113d1acc074544848b81e90d6272da09",
      "9070a8e54a7a4943b00c9a1dff9e8eeb",
      "1bad8f13f26045439192f13a09cf418f",
      "2d521fe36e464b468d4fc48c4b31f61d",
      "d81acde7222f48778d423c1cab70acde",
      "d9a26b76d819471f923a379d990b49a1"
     ]
    },
    "id": "J1P3zIz883c7",
    "outputId": "c32984f4-2390-4819-d974-c6443f1a7bce"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing results of 100 topics on shared pipeline component (pt.apply.query() >> TerrierRetr(BM25) >> pt.apply.generic())\n",
      "/opt/miniconda3/envs/rag/lib/python3.11/site-packages/pyterrier/pipelines.py:229: UserWarning: precompute_prefix with batch_size is very experimental. Please report any problems\n",
      "  warn(\"precompute_prefix with batch_size is very experimental. Please report any problems\")\n",
      "pt.Experiment precomputation: 100%|██████████| 4/4 [00:20<00:00,  5.11s/batches]\n",
      "pt.Experiment: 100%|██████████| 12/12 [01:50<00:00,  9.18s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "      <th>EM +</th>\n",
       "      <th>EM -</th>\n",
       "      <th>EM p-value</th>\n",
       "      <th>F1 +</th>\n",
       "      <th>F1 -</th>\n",
       "      <th>F1 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25 fid</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.265524</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.031801</td>\n",
       "      <td>4.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.020276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>monoT5_fid</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.351333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>monoT5 FlanT5 0z</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.272857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.250199</td>\n",
       "      <td>6.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.024181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               name    EM        F1  EM +  EM -  EM p-value  F1 +  F1 -  \\\n",
       "0          bm25 fid  0.17  0.265524   3.0  11.0    0.031801   4.0  18.0   \n",
       "1        monoT5_fid  0.25  0.351333   NaN   NaN         NaN   NaN   NaN   \n",
       "2  monoT5 FlanT5 0z  0.21  0.272857   4.0   8.0    0.250199   6.0  18.0   \n",
       "\n",
       "   F1 p-value  \n",
       "0    0.020276  \n",
       "1         NaN  \n",
       "2    0.024181  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [bm25_fid, monot5_fid, monoT5_flant5],\n",
    "    dataset.get_topics('dev').head(100), # NB: remove .head(100) to run on all dev topics\n",
    "    dataset.get_answers('dev'),\n",
    "    [pyterrier_rag.measures.F1, pyterrier_rag.measures.EM],\n",
    "    batch_size=25,\n",
    "    verbose=True,\n",
    "    precompute_prefix=True,\n",
    "    names=['bm25 fid', 'monoT5_fid', 'monoT5 FlanT5 0z'],\n",
    "    baseline=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5BOsFFLQCbT"
   },
   "source": [
    "From the results, we can see that MonoT5 with FiD was the most effective answer generator - 0.35 F1, 0.2 EM. Applying monoT5 to rerank the top 10 passages of BM25 improved the answers to 18 questions compared to raw BM25 (see F1- column). The improvement brought by monoT5 is significant for both F1 and EM (see the calculated p-values).\n",
    "\n",
    "FlanT5 gave a better answer than FiD for 5 questions (F1+), but degraded for 13 (F1-). FiD is likely better as it has been fine-tuned on the NQ dataset, while FlanT5 is used zero-shot. However, the difference is not statistically significant for either F1 nor EM (according to a paired t-test).\n",
    "\n",
    "FiD can be take more passages than just 3, as its context length is not limited. Let's see how well it does with a context length of 100 passages selected by monoT5. This experiments takes about 10 minutes on a Colab T4 GPU. Again, the BM25 results are pre-computed and reused for both pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 230,
     "referenced_widgets": [
      "c7f49301001046b8aac3673c9d8dd55a",
      "d3fd8276a40c47f9b3cc7009d85fba1a",
      "497cf13130a34f0581a3a2297f256ce7",
      "fa3381c6d1494bcb8335562a3a20009f",
      "8d8f92dcf8eb4990aeac0952794aed21",
      "e764a5921e2f4b4da8e4fa1a99b1d531",
      "a95ac45d3fc7486895f2564c1770de5e",
      "f775337cd7c54e9db8770c7a5ed7c6a3",
      "6ba279fe19e94affa9f62479292a6ac9",
      "23605a43b65e48f5a56fee5448d389a6",
      "80620f00eaff455ead92368eb866ef68",
      "08690d2b69064520906b6437edd128d0",
      "42308d28a4614a6dbd862856b5bb98c4",
      "35a559c59d104f3c802c203dbdd0adba",
      "bfdf4892253c4ed9943f57223ef96476",
      "d6f4a559b506410cbdf236ba79d03699",
      "964e9500b78f48bdad98038bd5d4a4e6",
      "a152099413814fbbae94748ecf2ede82",
      "bf3549bf55ac4be598095c8d2e1d591d",
      "75b0f85ca26341ebb4a76139d8854a42",
      "ea8598448e1f4ad694067228a43eaa66",
      "76a11c4c9bb640478c25c873d413f6a5"
     ]
    },
    "id": "RLzxs2J9sOZX",
    "outputId": "424b06dd-afc4-4c13-98db-46c5fcad1084"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing results of 100 topics on shared pipeline component (pt.apply.query() >> TerrierRetr(BM25) >> pt.apply.generic())\n",
      "/opt/miniconda3/envs/rag/lib/python3.11/site-packages/pyterrier/pipelines.py:229: UserWarning: precompute_prefix with batch_size is very experimental. Please report any problems\n",
      "  warn(\"precompute_prefix with batch_size is very experimental. Please report any problems\")\n",
      "pt.Experiment precomputation: 100%|██████████| 4/4 [00:06<00:00,  1.62s/batches]\n",
      "pt.Experiment: 100%|██████████| 8/8 [22:01<00:00, 165.21s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>EM</th>\n",
       "      <th>F1</th>\n",
       "      <th>EM +</th>\n",
       "      <th>EM -</th>\n",
       "      <th>EM p-value</th>\n",
       "      <th>F1 +</th>\n",
       "      <th>F1 -</th>\n",
       "      <th>F1 p-value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>monoT5 3p FiD</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.351333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>monoT5 100p FiD</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.547905</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.002304</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              name    EM        F1  EM +  EM -  EM p-value  F1 +  F1 -  \\\n",
       "0    monoT5 3p FiD  0.25  0.351333   NaN   NaN         NaN   NaN   NaN   \n",
       "1  monoT5 100p FiD  0.40  0.547905  20.0   5.0    0.002304  29.0   8.0   \n",
       "\n",
       "   F1 p-value  \n",
       "0         NaN  \n",
       "1    0.000013  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [monot5_fid, bm25_ret % 200 >> monoT5 % 100 >> fid],\n",
    "    dataset.get_topics('dev').head(100), # NB: remove .head(100) to run on all dev topics\n",
    "    dataset.get_answers('dev'),\n",
    "    [pyterrier_rag.measures.F1, pyterrier_rag.measures.EM],\n",
    "    precompute_prefix=True,\n",
    "    names=['monoT5 3p FiD', 'monoT5 100p FiD'],\n",
    "    baseline=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BG5qdxExxPAN"
   },
   "source": [
    "Great! According to F1, giving FiD 100 passages gives a significant improvement $(p<0.05)$ compared to 3 passages, improving the answers of 29 queries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLYuzyouyXGW"
   },
   "source": [
    "# That's all folks.\n",
    "\n",
    "There are lots of other retrievers possible in PyTerrier - for instance [query expansion](https://pyterrier.readthedocs.io/en/latest/rewrite.html), [doc2query](https://github.com/terrierteam/pyterrier_doc2query), [SPLADE learned sparse](https://github.com/cmacdonald/pyt_splade) or [dense retrieval](https://github.com/terrierteam/pyterrier_dr) (including the [ColBERT](https://github.com/terrierteam/pyterrier_colbert) multi-representation dense model).\n",
    "\n",
    "PyTerrier-RAG also provides easy access to lots of other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:rag]",
   "language": "python",
   "name": "conda-env-rag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
