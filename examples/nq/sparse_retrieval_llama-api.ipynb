{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g_o70WfKQFTd"
   },
   "source": [
    "# Sparse Retrieval for Natural Questions RAG\n",
    "\n",
    "This notebook demonstrates [PyTerrier](http://github.com/terrier-org/pyterrier) and [PyTerrier-RAG](https://github.com/terrierteam/pyterrier_rag). This notebooks runs on Google Colab if you select a Runtime with a T4 GPU (these are free to use), and will take approx. 12 minutes to execute fully."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w6iZau7_QP9v"
   },
   "source": [
    "## Installation\n",
    "\n",
    "Lets install what we need:\n",
    " - PyTerrier - core platform\n",
    " - PyTerrier_t5 - MonoT5 reranker\n",
    " - pyterrier_rag - Support for RAG datasets and answer generators (aka readers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uatJzx1kQ7_J",
    "outputId": "347f52f9-6439-4151-e098-c85994e8d81e"
   },
   "outputs": [],
   "source": [
    "#%pip install -q --root-user-action=ignore vllm pyterrier_t5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yvFoJULYRAqq",
    "outputId": "a52b7574-5fa7-4d21-ebcb-f77afe4b06d9"
   },
   "outputs": [],
   "source": [
    "#%pip install -q --root-user-action=ignore pyterrier-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kHFMfW1uPZhS"
   },
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "pt.utils.set_tqdm('notebook')\n",
    "import pyterrier_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KrI7rYO4Qeb2"
   },
   "source": [
    "## Retrievers\n",
    "\n",
    "Lets load a sparse index of Wikipedia. Conveniently, we've stored this as a [Huggingface dataset](https://huggingface.co/datasets/pyterrier/ragwiki-terrier). This is 12GB in size (it also contains the text of the documents) - downloading takes about 10 minutes on Google Colab.\n",
    "\n",
    "We'll use that index to get a BM25 retriever (you can see how this was created at https://huggingface.co/datasets/pyterrier/ragwiki-terrier#reproduction). \n",
    "\n",
    "Terrier doesnt like question marks in queries, so we'll strip these and restore them after.\n",
    "\n",
    "Finally, lets make a monoT5 reranker, we can use that to rerank BM25,\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783,
     "referenced_widgets": [
      "6390c0d2ef0e4ca5acf1530bc958ccae",
      "9062ea2922fc4a9687c22a35813cc13b",
      "af915153635a4480b299b769df35fc6e",
      "c38c083cabef431093eb443e93e52a1a",
      "c45314fbed7e4726865dd6cf6425fbea",
      "4be825db5ecb454cbe6c91af0becb3c5",
      "d53c269b5b6e4bab90130f81fc200834",
      "43c47090cd934ca6a34ef99888646cd0",
      "531e568d344b481985c95e444c10d2c0",
      "ea9bd020f78a4d16b16d73adfd373447",
      "3dfdd0041b15472fad7696e5ea9d692a",
      "d2aee0e3177d455483a2ac8382c3762b",
      "623b51385536462190565212d2b3a6c9",
      "500fb33008f54e998058cf4574919d07",
      "72a939bc0a014edf99ed72824226a0c4",
      "341d1ecf2b6d4608946e010276f1da84",
      "f4521b2151134ca4a6d54b4d31b7dbd0",
      "318d3f0c8c9d4f1a995bdf65b0895ad6",
      "2185643db9904fbcb8f127d23da15aa4",
      "13e58ae8c1474acba14fd08e8d9eddd7",
      "e6301414593d4f5098b63ca08a157ec8",
      "8a496a95dd504f8aa3cd1eec28e94aa2",
      "d7687d62fba0436382a3a731e299df57",
      "91551bd2ab6c430999a64275b590d938",
      "00eb6addc6da4f258eb9927a085e5d4e",
      "244c43e1b06346e6a56b21c99c44af69",
      "4e6ed91babcc49e7801b18285d5c756d",
      "992874a87acf415b8c2479e74c65dbe9",
      "36d13de0cb624e9a836f3bfda3516770",
      "19b06d7509844359a9b99941ee558a7a",
      "cdc7985ccd9d4573ba671075a4e794c1",
      "eb9546f23df04d0cb3257624fd79fd1c",
      "15d875b2559242ad82f926db09ffed33",
      "3bd15ac2d6814b3cb8ac31644c90d9bd",
      "0e6827007a854ccfa74f09d8f17d0ca7",
      "78497b79fe544af89322339fe3220dc4",
      "5d8f5335702a4822b0cbe90a9242e9ca",
      "11da3cc1945449a0a8bb94d71df08078",
      "28d5af1bfead42879f338dfbb99cccfa",
      "60999fb90db84a20a71368d4eae272bd",
      "175ac3f821ce472ca0e633c8d6d98b13",
      "dd6a16430bda4df0a45d5c4c9dbf11c6",
      "0fb30c69859942378ea925fa6b710e7e",
      "135dab5311a34e1692056ac4746b1a62",
      "4a1d22c856574b04a2f0045b26435edc",
      "4d10f9ff60a44c37b3395c82b608e5df",
      "5a0a28fad28542beb70fe8bb8841a6b6",
      "9e585fd56b8248ff836f3422d1debd93",
      "449940861e1349eaa7b2ba43afbb09fb",
      "61c8620217f948258a57a9b4d61c791f",
      "f7cef11c1f68455aac25a364c1a4157e",
      "7fe368acce2144eea9a7ee8c02210df6",
      "88525152c40743d4a0a0007f1218d4eb",
      "ef4fb8e3026945eba8185bb85fb214d6",
      "3d7216f1edf14b728abf77a55080c937",
      "38534fcb9a1246f9afcfbf303016778a",
      "ccfca650361a4020b9a46d4eeb90e5f3",
      "b44aded8c967484eb97eea2ef4ec5cdd",
      "4b5c7930c82245e3b476bce2515b723d",
      "56f26486dd144cdd9913812af1d3bae5",
      "04da27bde4f9464eb4ab7fb3e870cc7c",
      "bc694ecc84694c1088b7069b668a728f",
      "bda88bc8168443c5899ee3cea8c17cbe",
      "e1d93b72cebe49b4b97f7c8a83ee4e50",
      "75e46e5e7bf0423c9e4346176cd0f067",
      "1e7f428b71db46dfb1fe88c49d3cf92f"
     ]
    },
    "id": "BybUPDh6Qy33",
    "outputId": "9c859371-a566-496a-ebeb-19d4b84f848e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started (triggered by tokenise) and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n",
      "/opt/miniconda3/lib/python3.10/site-packages/pyterrier/terrier/retriever.py:219: UserWarning: Multi-threaded retrieval is experimental, YMMV.\n",
      "  warn(\n",
      "/opt/miniconda3/lib/python3.10/site-packages/pyterrier/terrier/retriever.py:226: UserWarning: Upgrading indexref /mnt/resources/pyterrier-cache/artifacts/ebfd80cc597a31719f11ab5cd11ad8f441bc460f760c82ff66413ba9fb06943f/data.properties to be concurrent\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "sparse_index = pt.Artifact.from_hf('pyterrier/ragwiki-terrier')\n",
    "bm25_ret = pt.rewrite.tokenise() >> sparse_index.bm25(include_fields=['docno', 'text', 'title'], threads=5) >> pt.rewrite.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "S8idFu1bRfh6",
    "outputId": "cde0d954-80b0-4a8f-8e99-c7999b2c109e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>docid</th>\n",
       "      <th>docno</th>\n",
       "      <th>text</th>\n",
       "      <th>title</th>\n",
       "      <th>rank</th>\n",
       "      <th>score</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1027780</td>\n",
       "      <td>1027780</td>\n",
       "      <td>Chemical change Chemical changes occur when a ...</td>\n",
       "      <td>\"Chemical change\"</td>\n",
       "      <td>0</td>\n",
       "      <td>29.908465</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>53321</td>\n",
       "      <td>53321</td>\n",
       "      <td>are called reactants or reagents. Chemical rea...</td>\n",
       "      <td>\"Chemical reaction\"</td>\n",
       "      <td>1</td>\n",
       "      <td>29.825437</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>860125</td>\n",
       "      <td>860125</td>\n",
       "      <td>Chemical reaction A chemical reaction is a pro...</td>\n",
       "      <td>\"Chemical reaction\"</td>\n",
       "      <td>2</td>\n",
       "      <td>29.526942</td>\n",
       "      <td>What are chemical reactions?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid    docid    docno                                               text  \\\n",
       "0   1  1027780  1027780  Chemical change Chemical changes occur when a ...   \n",
       "1   1    53321    53321  are called reactants or reagents. Chemical rea...   \n",
       "2   1   860125   860125  Chemical reaction A chemical reaction is a pro...   \n",
       "\n",
       "                 title  rank      score                         query  \n",
       "0    \"Chemical change\"     0  29.908465  What are chemical reactions?  \n",
       "1  \"Chemical reaction\"     1  29.825437  What are chemical reactions?  \n",
       "2  \"Chemical reaction\"     2  29.526942  What are chemical reactions?  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(bm25_ret%3).search(\"What are chemical reactions?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CuYGD1c4RCdx"
   },
   "source": [
    "## Readers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyterrier_rag.backend import OpenAIBackend\n",
    "from pyterrier_rag.prompt import Concatenator\n",
    "from pyterrier_rag.readers import Reader\n",
    "from pyterrier_rag.prompt import PromptTransformer, prompt\n",
    "\n",
    "from fastchat.model import get_conversation_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"llama-3-8b-instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = r\"\"\"You are an expert Q&A system that is trusted around the world. \n",
    "        Always answer the query using the provided context information,\n",
    "        and not prior knowledge.\n",
    "        Some rules to follow:\n",
    "        1. Never directly reference the given context in your answer\n",
    "        2. Avoid statements like 'Based on the context, ...' or \n",
    "        'The context information ...' or anything along those lines.\"\"\"\n",
    "prompt_text = \"\"\"Context information is below.\n",
    "            ---------------------\n",
    "            {{ qcontext }}\n",
    "            ---------------------\n",
    "            Given the context information and not prior knowledge, answer the query.\n",
    "            Query: {{ query }}\n",
    "            \"Answer: \"\"\"\n",
    "\n",
    "template = get_conversation_template(\"meta-llama-3.1-sp\")\n",
    "prompt = PromptTransformer(\n",
    "    conversation_template=template,\n",
    "    system_message=system_message,\n",
    "    instruction=prompt_text,\n",
    "    api_type=\"openai\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 209,
     "referenced_widgets": [
      "be7da14a151b45b0abb1baafb7e88993",
      "55634ab2259640d288f61815a948e512",
      "e817d5b418d94c7088264c1db8547fed",
      "f770920ee9084dd492c396535d8f4bcf",
      "990d4e4cf8444eacba298043a791df21",
      "4fff7a74678740eab6c2b6eadef66fd9",
      "02305c87e8ee499aacc68cad59016aae",
      "62a3fbdeef1b496ea0848f527447ff14",
      "0c82a75e57ae4c21ab54979c5f8bab1d",
      "9f9a5ed0cf0a4e1aa5aff88b2bdc69b8",
      "4210fdbe21d74264a6ff71b350037136",
      "ad6cd3ea8f4f4e99a5b8056c8d374606",
      "145b56f8b10741a88c1460eda88f4378",
      "7b92eb472d8b45859437ebf18415acc6",
      "1ed0b9960e4d4925a3c08a1e70a145dd",
      "382347e1bb7d4fdfa727db905ca4779f",
      "b58d0267f1c048d299d9899b6df6f1aa",
      "eb09336a8d9e496e845e3631599e5411",
      "cd098a515a884839acd1e29507c9d37a",
      "661a2cd4f843428b880b0017d7d63d0f",
      "18ce6263244f444484c28c3398a53ea0",
      "b992877edc184ac299aeaefff99e0177",
      "8b725c45da554d5cb2483ff292f0ba20",
      "2a7f9f438e32413893b1d9faadbc24e4",
      "b1e4e1ae19fc48cf945e6256abc6bd03",
      "1180cba9eedb4cadb1366a9a5ae1bef0",
      "f4c0c2925fd84d9ba727d0c3e4161dc1",
      "85c72d08334d42e6872445e352537693",
      "09cc45c92c044b49ace60233d3db9204",
      "c362e9cea66749c3ad5879eec0c99a20",
      "12bf293b38754c71adba7f9a86f9379c",
      "4a6f8879166d4266a1733d174488e052",
      "793ad289385142b7b55cf9f4428db9ae",
      "3f53b8aa84954ab6abc6d6f5f098d891",
      "e0a49a73f6784a7f80b5af6afe6dd9dd",
      "c34e43f299014e729fd71edefa1456f0",
      "d4941bffa4454135a7e28912b796e28a",
      "e722237e5ea94fbfaf7f955d2564d2c5",
      "f259978c7fe8406c81ee4a9481471188",
      "ede98007980a452a97776bf84f01382b",
      "d5900dd4a5cc414aac1b943e245081f5",
      "ef583dd749d4425abeb5741fe76a4c48",
      "cab94417c0034ade9d83d0026c45779a",
      "99e3289ad8d3428cab5221d655310004",
      "0306f8cd525641f2ac79a140ced16db9",
      "1f55f256db92438bbb1786cf828a6dd3",
      "9eb9adbd507b4861a34f05cd5398dd51",
      "0124987d38834155bdbdac7c5f2262e9",
      "1ad55368a5294e0e83e5157cea1b89c5",
      "4a603ab9be704e3ab38cbd48716190c9",
      "5c251032748c478ebed87e4f753d31f4",
      "9706429f4bb9407eaac351e7f3695486",
      "5cf3f19ebcbb491bb6b96b2875d10399",
      "c3b75d20fcba4a84bdbb679d9fefc464",
      "d2250486a0ca4ce08e8827536ebfef5d",
      "b34eca238a6e4d46978bc1338beb76ab",
      "9fb9ab2aebed4a999d382d8f3e950fb2",
      "63085e000d2742fbb6002f32f1108bea",
      "5daf8270330e49c086c4457679ab821f",
      "a720275c96e34353b2ed3850dcd62e59",
      "818ca82fa230476e9747a5ed5cd555c8",
      "a5753e98ec13461282b7440774875cb5",
      "3f0978aaa55c4cc5b56b170df62eb309",
      "b52bdab8efa14fdaa4ba68f01ac73b3b",
      "f2caaf8f265246e3a80253c09bc15500",
      "dbf4c12cce6d4342bd5171b60daa7793"
     ]
    },
    "id": "1uUqwgkSRRkk",
    "outputId": "0ca5ebd4-8e59-4847-81a3-9444a6d51b0a"
   },
   "outputs": [],
   "source": [
    "\n",
    "generation_args={\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_tokens\": 128,\n",
    "}\n",
    "\n",
    "# this could equally be a real OpenAI models\n",
    "llama = OpenAIBackend(model_name, \n",
    "                      api_key=\"ida_0sjUm0LEoXlnDsdJV19hvyVfpyxvubmGZGBTiops\", \n",
    "                      generation_args=generation_args,\n",
    "                      base_url=\"http://api.llm.apps.os.dcs.gla.ac.uk/v1\")\n",
    "\n",
    "llama_reader = Reader(llama, prompt=prompt)\n",
    "bm25_llama = bm25_ret % 5 >> Concatenator() >> llama_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = bm25_llama.search(\"what are chemical reactions?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A process that leads to the chemical transformation of one set of chemical substances to another.\n"
     ]
    }
   ],
   "source": [
    "print(results.iloc[0].qanswer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APGF5E99RrlR"
   },
   "source": [
    "# Datasets & Experiments\n",
    "\n",
    "Lets compare the effectiveness of this approach on the Natural Questions dataset. These topics are automatically downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "W--MmMYZSqSP",
    "outputId": "7a72e880-1eb8-4bc0-c60c-1a69595688d5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_0</td>\n",
       "      <td>who sings does he love me with reba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_1</td>\n",
       "      <td>how many pages is invisible man by ralph ellison</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                                             query\n",
       "0  dev_0               who sings does he love me with reba\n",
       "1  dev_1  how many pages is invisible man by ralph ellison"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset('rag:nq')\n",
    "dataset.get_topics('dev').head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "scU0jppYSz3C"
   },
   "source": [
    "And their corresponding gold truth answers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 112
    },
    "id": "ESvmPzxYSwr4",
    "outputId": "6af066c0-0c0a-4968-81b9-e44ce5af7322"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>gold_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_0</td>\n",
       "      <td>who sings does he love me with reba</td>\n",
       "      <td>Linda Davis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_1</td>\n",
       "      <td>how many pages is invisible man by ralph ellison</td>\n",
       "      <td>581 (second edition)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     qid                                             query  \\\n",
       "0  dev_0               who sings does he love me with reba   \n",
       "1  dev_1  how many pages is invisible man by ralph ellison   \n",
       "\n",
       "            gold_answer  \n",
       "0           Linda Davis  \n",
       "1  581 (second edition)  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_topics('dev').head(2).merge(dataset.get_answers('dev'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N0I13hlRSubW"
   },
   "source": [
    "Now lets run an experiment using Natural Questions.\n",
    "\n",
    "Here we only have one pipeline - bm25_mistral.\n",
    "\n",
    "The additional arguments are:\n",
    " - `batch_size` - how many queries to run and evalate at once. Not always necessary, but makes the progress bars more granular\n",
    " - `verbose` - display progress bars for this experiment\n",
    " - `precompute_prefix` - optimise the experiment such that BM25 is only computed once.\n",
    " - `names` - for naming rows in the output dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 261,
     "referenced_widgets": [
      "0b906a0b2bac4b5c82f6e0e755c741c3",
      "9bb0dba3926443d5accb32fc4d80c2f3",
      "9d4c6e635ab7446b9e0251f25f3be922",
      "fa1c9fd792374b209a86238bb12887d2",
      "7575e4075e7d4160b0db458d50446ce1",
      "82b5af984be14d3da362ad5b57410e74",
      "aecd5d1faa6b41a9b7bf78f2e7bec9b0",
      "4551e6e37d494519bc36f8ad9cc710ed",
      "819d1c120f4d498fa9d63633f9462e76",
      "c3c4a2936498494c9bca162012237484",
      "745f2a10770843b988e9367aab21b193",
      "baa8e017f9e24b8785ebcafbd036ec26",
      "fbcac39d19044cca86fb7d8e03ead7ee",
      "acef8f3219ec4156878e4fde76373e67",
      "2587e313646540b0ae84b11e703852d8",
      "3c2b33cee12e4bfb83fa2d5bf9d67c6b",
      "113d1acc074544848b81e90d6272da09",
      "9070a8e54a7a4943b00c9a1dff9e8eeb",
      "1bad8f13f26045439192f13a09cf418f",
      "2d521fe36e464b468d4fc48c4b31f61d",
      "d81acde7222f48778d423c1cab70acde",
      "d9a26b76d819471f923a379d990b49a1"
     ]
    },
    "id": "J1P3zIz883c7",
    "outputId": "c32984f4-2390-4819-d974-c6443f1a7bce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03a273260a234b38a0d158e04011486e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pt.Experiment:   0%|          | 0/4 [00:00<?, ?batches/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>F1</th>\n",
       "      <th>EM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bm25 llama</td>\n",
       "      <td>0.312947</td>\n",
       "      <td>0.21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name        F1    EM\n",
       "0  bm25 llama  0.312947  0.21"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt.Experiment(\n",
    "    [bm25_llama],\n",
    "    dataset.get_topics('dev').head(100), # NB: remove .head() to run on all dev topics\n",
    "    dataset.get_answers('dev'),\n",
    "    [pyterrier_rag.measures.F1, pyterrier_rag.measures.EM],\n",
    "    batch_size=25,\n",
    "    verbose=True,\n",
    "    names=['bm25 llama'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sLYuzyouyXGW"
   },
   "source": [
    "# That's all folks.\n",
    "\n",
    "There are lots of other retrievers possible in PyTerrier - for instance [query expansion](https://pyterrier.readthedocs.io/en/latest/rewrite.html), [doc2query](https://github.com/terrierteam/pyterrier_doc2query), [SPLADE learned sparse](https://github.com/cmacdonald/pyt_splade) or [dense retrieval](https://github.com/terrierteam/pyterrier_dr) (including the [ColBERT](https://github.com/terrierteam/pyterrier_colbert) multi-representation dense model).\n",
    "\n",
    "PyTerrier-RAG also provides easy access to lots of other datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
