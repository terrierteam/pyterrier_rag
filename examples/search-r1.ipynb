{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "422d13ff-b4ac-4754-bb63-8a02e3897a92",
   "metadata": {},
   "source": [
    "# Search-R1\n",
    "\n",
    "This is a model trained to generated queries as part of its inference process. The original implementation is from infer.py in https://github.com/PeterGriffinJin/Search-R1 by the original authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7e8410-291c-4db0-8134-841f868106f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q python-terrier accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23965e2-f283-48fc-b41b-e16f69e2ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import pyterrier_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10847b72-6863-40ef-8841-acf5be972a20",
   "metadata": {},
   "source": [
    "## Retrieval Setup\n",
    "\n",
    "Lets get a BM25 retriever. This (Terrier) retriever also has the 'text', 'title' metadata for passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662cafbc-dcfb-4fb7-aeb3-8fef084bce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started (triggered by tokenise) and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:50.500 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading lookup file directly from disk (SLOW) - try index.meta.index-source=fileinmem in the index properties file. 160.3 MiB of memory would be required.\n",
      "21:54:50.515 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 8.2 GiB of memory would be required.\n"
     ]
    }
   ],
   "source": [
    "sparse_index = pt.Artifact.from_hf('pyterrier/ragwiki-terrier')\n",
    "\n",
    "# queries from R1 may have tokens that Terrier doesnt like. We can remove them and put them back later.\n",
    "bm25 = pt.rewrite.tokenise() >> sparse_index.bm25(include_fields=['docno', 'text', 'title']) >> pt.rewrite.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b3726-0618-4154-9403-baa8cafee837",
   "metadata": {},
   "source": [
    "## Search-R1 model\n",
    "\n",
    "We invoke SearchR1 using our BM25 retrieval pipeline. By default, SearchR1 takes only 3 passages from the specified retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51021048-595f-467d-8062-de63d6aff766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e150386270743fea71d0c78341905de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r1_bm25 = pyterrier_rag.SearchR1(bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037b3a2-570b-4664-848e-3fbf0e420460",
   "metadata": {},
   "source": [
    "Lets try it out. We get back a dataframe with one row, which has the generated answer in the qanswer column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8abb1807-40a5-4ec6-a43a-f71c1914f2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "qid                                                            1\n",
       "query                               what are chemical reactions?\n",
       "qanswer        chemical transformation of one set of chemical...\n",
       "output         <think>I found out that chemical reactions are...\n",
       "iteration                                                      1\n",
       "all_queries                 [(0,  what are chemical reactions )]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r1_bm25.search(\"what are chemical reactions?\").iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e39e10-ac47-41e9-8555-c631e7abd146",
   "metadata": {},
   "source": [
    "## Improving the Retriever\n",
    "\n",
    "As SearchR1 takes only the top 3 passages, the precision is very important. Lets rerank the top 20 passages using the MonoT5 cross-encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a70ecb6-75f1-4d82-a7ec-609323a3cece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 52.99batches/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "qid                                                            1\n",
       "query                               what are chemical reactions?\n",
       "qanswer        chemical transformation of one set of chemical...\n",
       "output         <think>I found out that chemical reactions are...\n",
       "iteration                                                      1\n",
       "all_queries                 [(0,  what are chemical reactions )]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier_t5 import MonoT5ReRanker\n",
    "monoT5 = MonoT5ReRanker()\n",
    "r1_monoT5 = r1_bm25.clone_for_retriever(bm25 % 20 >> monoT5)\n",
    "r1_monoT5.search(\"what are chemical reactions?\").iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2199ef5-f8ff-4c58-9c88-5ecca3cd25ad",
   "metadata": {},
   "source": [
    "In this case, it seems the answer stayed the same. But lets see if mattered quantitively..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaacb10-32ea-4f42-a07c-19b126bb1b7c",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now lets run a quick experiment using Natural Questions, comparing our two R1 invocations. I'm also going to add a custom measure to see how many (search/thought) iterations were used by the two settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e79c6e1b-3c9f-4692-b388-28b02c193df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment:  50%|█████     | 1/2 [00:12<00:12, 12.73s/batches]\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 51.11batches/s]\n",
      "\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 51.66batches/s]\n",
      "\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 50.90batches/s]\n",
      "\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 52.87batches/s]\n",
      "\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 52.82batches/s]\n",
      "\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 53.04batches/s]\n",
      "\n",
      "monoT5:   0%|          | 0/5 [00:00<?, ?batches/s]\u001b[A\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 49.14batches/s]\u001b[A\n",
      "pt.Experiment: 100%|██████████| 2/2 [00:25<00:00, 12.95s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>F1</th>\n",
       "      <th>EM</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1(BM25)</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1(monoT5)</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name        F1   EM  Iterations\n",
       "0    R1(BM25)  0.333333  0.0         3.5\n",
       "1  R1(monoT5)  0.500000  0.5         3.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset('rag:nq')\n",
    "from ir_measures import define_byquery\n",
    "Iterations = define_byquery(lambda qrels, run: run.iloc[0].iteration, name=\"Iterations\")\n",
    "pt.Experiment(\n",
    "    [r1_bm25, r1_monoT5],\n",
    "    dataset.get_topics('dev').head(2), # NB: remove .head(100) to run on all dev topics\n",
    "    dataset.get_answers('dev'),\n",
    "    [pyterrier_rag.measures.F1, pyterrier_rag.measures.EM, Iterations],\n",
    "    batch_size=25,\n",
    "    verbose=True,\n",
    "    names=['R1(BM25)', 'R1(monoT5)']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63677a1d-5c8d-4b58-9d1d-02a48439a9f9",
   "metadata": {},
   "source": [
    "## What about Dense Retrieval\n",
    "\n",
    "Don't fear, there is a dense index for wiki available.... Instructions coming soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a190e440-63e6-4508-9fef-f3afef425c14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rag]",
   "language": "python",
   "name": "conda-env-rag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
