{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "422d13ff-b4ac-4754-bb63-8a02e3897a92",
   "metadata": {},
   "source": [
    "# Search-R1\n",
    "\n",
    "This is a model trained to generated queries as part of its inference process. The original implementation is from infer.py in https://github.com/PeterGriffinJin/Search-R1 by the original authors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c7e8410-291c-4db0-8134-841f868106f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install -q python-terrier accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c23965e2-f283-48fc-b41b-e16f69e2ac3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyterrier as pt\n",
    "import pyterrier_rag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10847b72-6863-40ef-8841-acf5be972a20",
   "metadata": {},
   "source": [
    "## Retrieval Setup\n",
    "\n",
    "Lets get a BM25 retriever. This (Terrier) retriever also has the 'text', 'title' metadata for passages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662cafbc-dcfb-4fb7-aeb3-8fef084bce5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Java started (triggered by tokenise) and loaded: pyterrier.java, pyterrier.terrier.java [version=5.11 (build: craig.macdonald 2025-01-13 21:29), helper_version=0.0.8]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:54:50.500 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading lookup file directly from disk (SLOW) - try index.meta.index-source=fileinmem in the index properties file. 160.3 MiB of memory would be required.\n",
      "21:54:50.515 [main] WARN org.terrier.structures.BaseCompressingMetaIndex -- Structure meta reading data file directly from disk (SLOW) - try index.meta.data-source=fileinmem in the index properties file. 8.2 GiB of memory would be required.\n"
     ]
    }
   ],
   "source": [
    "sparse_index = pt.Artifact.from_hf('pyterrier/ragwiki-terrier')\n",
    "\n",
    "# queries from R1 may have tokens that Terrier doesnt like. We can remove them and put them back later.\n",
    "bm25 = pt.rewrite.tokenise() >> sparse_index.bm25(include_fields=['docno', 'text', 'title']) >> pt.rewrite.reset()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b3726-0618-4154-9403-baa8cafee837",
   "metadata": {},
   "source": [
    "## Search-R1 model\n",
    "\n",
    "We invoke SearchR1 using our BM25 retrieval pipeline. By default, SearchR1 takes only 3 passages from the specified retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51021048-595f-467d-8062-de63d6aff766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e150386270743fea71d0c78341905de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "r1_bm25 = pyterrier_rag.SearchR1(bm25)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037b3a2-570b-4664-848e-3fbf0e420460",
   "metadata": {},
   "source": [
    "Lets try it out. We get back a dataframe with one row, which has the generated answer in the qanswer column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8abb1807-40a5-4ec6-a43a-f71c1914f2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qid</th>\n",
       "      <th>query</th>\n",
       "      <th>qanswer</th>\n",
       "      <th>output</th>\n",
       "      <th>iteration</th>\n",
       "      <th>all_queries</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>what are chemical reactions?</td>\n",
       "      <td>a process that results in the interconversion ...</td>\n",
       "      <td>&lt;think&gt;I found out that chemical reactions are...</td>\n",
       "      <td>2</td>\n",
       "      <td>[(0,  what are chemical reactions ), (1,  chem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  qid                         query  \\\n",
       "0   1  what are chemical reactions?   \n",
       "\n",
       "                                             qanswer  \\\n",
       "0  a process that results in the interconversion ...   \n",
       "\n",
       "                                              output  iteration  \\\n",
       "0  <think>I found out that chemical reactions are...          2   \n",
       "\n",
       "                                         all_queries  \n",
       "0  [(0,  what are chemical reactions ), (1,  chem...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = r1_bm25.search(\"what are chemical reactions?\")\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a8d04b-3997-4eb8-956e-a46e2c75e4d5",
   "metadata": {},
   "source": [
    "We can see the answer in the qanswer column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc389af8-539d-4af5-86d7-b2ccac8a00f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a process that results in the interconversion of chemical species'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.iloc[0].qanswer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dfaabf-e588-4207-abcf-f9576966c36b",
   "metadata": {},
   "source": [
    "The all_queries column shows the queries that were passed to the search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "92139b8c-1521-4a77-8993-6d4b72ededac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, ' what are chemical reactions '), (1, ' chemical reactions definition ')]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.iloc[0].all_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2698d6a-e754-4f0c-a8ca-b18118517dff",
   "metadata": {},
   "source": [
    "Finally, we can also see the full output of the model, including its reasoning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9471202b-358f-4d1c-a223-4212abc845d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>I found out that chemical reactions are processes that result in the interconversion of chemical species. Now I can provide the answer.</think>\n",
      "\n",
      "<answer> a process that results in the interconversion of chemical species </answer>\n"
     ]
    }
   ],
   "source": [
    "print(res.iloc[0].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e39e10-ac47-41e9-8555-c631e7abd146",
   "metadata": {},
   "source": [
    "## Improving the Retriever\n",
    "\n",
    "As SearchR1 takes only the top 3 passages, the precision is very important. Lets rerank the top 20 passages using the MonoT5 cross-encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a70ecb6-75f1-4d82-a7ec-609323a3cece",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "monoT5: 100%|██████████| 5/5 [00:00<00:00, 52.99batches/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "qid                                                            1\n",
       "query                               what are chemical reactions?\n",
       "qanswer        chemical transformation of one set of chemical...\n",
       "output         <think>I found out that chemical reactions are...\n",
       "iteration                                                      1\n",
       "all_queries                 [(0,  what are chemical reactions )]\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyterrier_t5 import MonoT5ReRanker\n",
    "monoT5 = MonoT5ReRanker()\n",
    "r1_monoT5 = r1_bm25.clone_for_retriever(bm25 % 20 >> monoT5)\n",
    "r1_monoT5.search(\"what are chemical reactions?\").iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2199ef5-f8ff-4c58-9c88-5ecca3cd25ad",
   "metadata": {},
   "source": [
    "So lets see if using monoT5 quantitively improved the results..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aaacb10-32ea-4f42-a07c-19b126bb1b7c",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Now lets run a quick experiment using Natural Questions, comparing our two R1 invocations. I'm also going to add a custom measure to see how many (search/thought) iterations were used by the two settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e79c6e1b-3c9f-4692-b388-28b02c193df5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pt.Experiment: 100%|██████████| 8/8 [19:32<00:00, 146.58s/batches]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>F1</th>\n",
       "      <th>EM</th>\n",
       "      <th>Iterations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1(BM25)</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.34</td>\n",
       "      <td>2.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1(monoT5)</td>\n",
       "      <td>0.531571</td>\n",
       "      <td>0.44</td>\n",
       "      <td>2.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         name        F1    EM  Iterations\n",
       "0    R1(BM25)  0.433000  0.34        2.48\n",
       "1  R1(monoT5)  0.531571  0.44        2.20"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pt.get_dataset('rag:nq')\n",
    "from ir_measures import define_byquery\n",
    "Iterations = define_byquery(lambda qrels, run: run.iloc[0].iteration, name=\"Iterations\")\n",
    "pt.Experiment(\n",
    "    [r1_bm25, r1_monoT5],\n",
    "    dataset.get_topics('dev').head(100), # NB: remove .head(100) to run on all dev topics\n",
    "    dataset.get_answers('dev'),\n",
    "    [pyterrier_rag.measures.F1, pyterrier_rag.measures.EM, Iterations],\n",
    "    batch_size=25,\n",
    "    verbose=True,\n",
    "    names=['R1(BM25)', 'R1(monoT5)']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc61b2d0-ceb3-4aeb-a649-64b60f46cfaa",
   "metadata": {},
   "source": [
    "So here, using monoT5 over BM25 improves the answer quality (both F1 and EM), and reduced the number of iterations..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63677a1d-5c8d-4b58-9d1d-02a48439a9f9",
   "metadata": {},
   "source": [
    "## What about Dense Retrieval?\n",
    "\n",
    "Don't fear, there is a dense index for wiki available.... Instructions coming soon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rag]",
   "language": "python",
   "name": "conda-env-rag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
